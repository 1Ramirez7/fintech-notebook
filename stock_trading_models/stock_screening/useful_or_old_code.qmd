---
title: "python_test"
format: html
---








**This chunk gets Setor and industry names.**

```{python}
# This chunk gets Setor and industry names.
# ticker column must just have ticker symbol only

import yfinance as yf
import pandas as pd

# Load Excel file
file_path = r"data/ticker_sample.xlsx"
df = pd.read_excel(file_path)

# Get sector and industry info
def get_sector_industry(ticker):
    try:
        info = yf.Ticker(ticker).info
        return pd.Series([info.get("sector"), info.get("industry")])
    except:
        return pd.Series([None, None])

# Apply to Ticker column
df[["Sector", "Industry"]] = df["ticker"].apply(get_sector_industry)

# Save updated file
output_path = r"data/ticker_sample_one.xlsx"
df.to_excel(output_path, index=False)


```





**Plot stock time series price**

This code is stand alone as the code that replace this can a pre laod chunk that loads the ticker data first. So when re running the plot code I dont run the load process all over again

```{r}
# As I expand ticker screening, need to figure out system to preload ticker info only. 
# to load faster, and not read the entire database each time.
# this is common in sites, once you pick the stocks it sort of loads everything related to it so when reports are requested it is faster to load, as it is not searching through all ticker info but just the selected one . 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(googledrive, readr, dplyr, ggplot2, lubridate, plotly)

# ── PARAMETERS ─────────────────────────────────────────────
ticker <- "CARM"
date_start <- as.Date("2025-06-10")
date_end <- as.Date("2025-06-25")
# ───────────────────────────────────────────────────────────

# load google drive file
if (!googledrive::drive_has_token()) {googledrive::drive_auth()} 
file <- drive_get(path = "stock_data/fact_close_price.csv")

# Download to temporary path
temp_path <- tempfile(fileext = ".csv")
drive_download(file, path = temp_path, overwrite = TRUE)

# Chunked read and filter
filtered_data <- list()

chunk_callback <- function(x, pos) {
  x <- x |>
    filter(ticker == !!ticker)

  if (nrow(x) > 0) {
    filtered_data[[length(filtered_data) + 1]] <<- x
  }
}

read_csv_chunked(
  file = temp_path,
  callback = SideEffectChunkCallback$new(chunk_callback),
  chunk_size = 100000,
  col_types = cols_only(
    ticker = col_character(),
    date = col_character(),
    close_price = col_double(),
    dayHigh = col_double(),
    dayLow = col_double()
  )
)

# Combine filtered chunks
df <- bind_rows(filtered_data) |>
  mutate(date = as.Date(date)) |>
  filter(date >= date_start & date <= date_end)

# Plot
plot_ly(df, x = ~date) %>%
  add_trace(y = ~close_price, type = 'scatter', mode = 'lines', name = 'Close Price') %>%
  add_trace(y = ~dayHigh, type = 'scatter', mode = 'lines', name = 'Day High', line = list(dash = 'dot')) %>%
  add_trace(y = ~dayLow, type = 'scatter', mode = 'lines', name = 'Day Low', line = list(dash = 'dot')) %>%
  layout(
    title = list(
      text = paste0(ticker, " Price Range: ", date_start, " to ", date_end),
      x = 0.05
    ),
    xaxis = list(title = "Date"),
    yaxis = list(title = "Price"),
    legend = list(x = 0.01, y = 0.99)
  )


```






























































































































































































































































































































































































































































































spacer